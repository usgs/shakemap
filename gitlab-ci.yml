workflow:
  # Name the pipeline
  name: "Pipeline for branch: $CI_COMMIT_BRANCH , tag: $CI_COMMIT_TAG"

  # Run the pipeline jobs under merge requests, or with a certain git tag
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_TAG == "ci_tests"

# Need to use Conda to build Shakemap, pull the Docker image
default:
  image: ${DEVOPS_REGISTRY}usgs/conda:latest
  tags:
    - development

# For now, just set up a testing stagge to run PyTest
stages:
  - test

# Create parallel pipeline and job version configuration
.versions:
  parallel:
    matrix:
      - PYTHON_VERSION: ["3.9", "3.10"]

# Create reusable build configuration for referencing
.build_config:
  script:
    - source /etc/profile.d/conda.sh
    - conda init bash
    - conda install git
    - conda install python=${PYTHON_VERSION}
    - bash install.sh
    - export PATH="/home/usgs-user/.local/bin:$PATH"
    - echo ${PATH}
    - pwd
    - source activate shakemap

# Create test job
Test Build:
  stage: test
  script:
    # Run build configuration script
    - !reference [.build_config, script]

    # Continue job script
    - py.test --cov=. --cov-report=xml

  # Define test coverage and reporting
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

  # Run the jobs as parallel pipelines
  parallel: !reference [.versions, parallel]
