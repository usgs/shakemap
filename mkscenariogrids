#!/usr/bin/env python


import os
import subprocess
import xml.etree.ElementTree as ET
import argparse
import ast
import warnings

import numpy as np

#--------------------------------------------------
# WUS GMPEs
from openquake.hazardlib.gsim.abrahamson_2014 import AbrahamsonEtAl2014
from openquake.hazardlib.gsim.boore_2014 import BooreEtAl2014
from openquake.hazardlib.gsim.campbell_bozorgnia_2014 import CampbellBozorgnia2014
from openquake.hazardlib.gsim.chiou_youngs_2014 import ChiouYoungs2014

#--------------------------------------------------
# CEUS GMPEs
from openquake.hazardlib.gsim.frankel_1996 import FrankelEtAl1996MwNSHMP2008
# Note: the Toro implementation includes the 2002 update.
from openquake.hazardlib.gsim.toro_1997 import ToroEtAl1997MwNSHMP2008
from openquake.hazardlib.gsim.silva_2002 import SilvaEtAl2002MwNSHMP2008
from openquake.hazardlib.gsim.campbell_2003 import Campbell2003MwNSHMP2008
from openquake.hazardlib.gsim.tavakoli_pezeshk_2005 import TavakoliPezeshk2005MwNSHMP2008
from openquake.hazardlib.gsim.atkinson_boore_2006 import AtkinsonBoore2006Modified2011
from openquake.hazardlib.gsim.pezeshk_2011 import PezeshkEtAl2011
from openquake.hazardlib.gsim.boore_atkinson_2011 import Atkinson2008prime
from openquake.hazardlib.gsim.somerville_2001 import SomervilleEtAl2001NSHMP2008

#--------------------------------------------------
# SZ/interface GMPEs
# Note: do not use the "NSHMP" veresions of the subduction zone gmpes because they fix
#       hypocentral depth at 20 km.
from openquake.hazardlib.gsim.atkinson_boore_2003 import AtkinsonBoore2003SInter
from openquake.hazardlib.gsim.zhao_2006 import ZhaoEtAl2006SInter
from openquake.hazardlib.gsim.atkinson_macias_2009 import AtkinsonMacias2009
from openquake.hazardlib.gsim.abrahamson_2015 import AbrahamsonEtAl2015SInter

# SZ/intraslab GMPEs
from openquake.hazardlib.gsim.atkinson_boore_2003 import AtkinsonBoore2003SSlab
from openquake.hazardlib.gsim.atkinson_boore_2003 import AtkinsonBoore2003SSlabCascadia
from openquake.hazardlib.gsim.zhao_2006 import ZhaoEtAl2006SSlab
from openquake.hazardlib.gsim.abrahamson_2015 import AbrahamsonEtAl2015SSlab

#--------------------------------------------------
# Openquake utilities
from openquake.hazardlib.geo.utils import get_orthographic_projection
from openquake.hazardlib import imt, const
from openquake.hazardlib.gsim.base import SitesContext, DistancesContext, RuptureContext

from mapio.geodict import GeoDict
from mapio.gmt import GMTGrid

# Shakemap imports
import shakemap.grind.fault as fault
from shakemap.grind.source import Source
from shakemap.grind.distance import Distance
from shakemap.grind.sites import Sites
import shakemap.grind.multigmpe as mg
from shakemap.grind.directivity.rowshandel2013 import Rowshandel2013
from shakemap.utils.timeutils import ShakeDateTime
from shakemap.grind.gmice.wgrw12 import WGRW12
from shakemap.utils.misc import get_command_output

#----------------------------------------------------
# Function to compute extent from source
#----------------------------------------------------
def get_extent(source):
    # Note: currently written assuming source has a fault
    flt = source.getFault()
    lats = flt.getLats()
    lons = flt.getLons()
    clat = 0.5 * (np.nanmax(lats) + np.nanmin(lats))
    clon = 0.5 * (np.nanmax(lons) + np.nanmin(lons))
    mag = source.getEventParam('mag')
    if mag < 6.48:
        mindist_km = 100.
    else:
        # Note: This is an approximate equation developed for ACR/WUS.
        #       Probably should redo for SCR/CEUS.
        #       Would be useful to have tectonic environment stored in
        #       source object.
        mindist_km = 27.24 * mag**2 - 250.4 * mag + 579.1
    # Projection
    proj = get_orthographic_projection(clon - 4, clon + 4, clat + 4, clat - 4)
    fltx, flty = proj(lons, lats)
    xmin = np.nanmin(fltx) - mindist_km
    ymin = np.nanmin(flty) - mindist_km
    xmax = np.nanmax(fltx) + mindist_km
    ymax = np.nanmax(flty) + mindist_km
    dx = xmax - xmin
    dy = ymax - ymin
    ar = dy / dx
    if ar > 1.25:
        # Inflate x
        dx_target = dy / 1.25
        ddx = dx_target - dx
        xmax = xmax + ddx / 2
        xmin = xmin - ddx / 2
    if ar < 0.6:
        # inflate y
        dy_target = dx * 0.6
        ddy = dy_target - dy
        ymax = ymax + ddy / 2
        ymin = ymin - ddy / 2
    lonmin, latmin = proj(np.array([xmin]), np.array([ymin]), reverse=True)
    lonmax, latmax = proj(np.array([xmax]), np.array([ymax]), reverse=True)

    return lonmin, lonmax, latmin, latmax


def main(args):
    id_str = args.event
    if args.shakehome:
        shakehome = args.shakehome
    else:
        shakehome = os.path.join(os.path.expanduser('~'), 'ShakeMap')
    datdir = os.path.join(shakehome, 'data')
    evt_dir = os.path.join(datdir, id_str)
    input_dir = os.path.join(evt_dir, 'input')
    xml_file = os.path.join(input_dir, 'event.xml')

    #------------------
    # Read in event.xml
    #------------------
    eventtree = ET.parse(xml_file)
    eventroot = eventtree.getroot()
    for eq in eventroot.iter('earthquake'):
        magnitude = float(eq.attrib['mag'])
        hlat = float(eq.attrib['lat'])
        hlon = float(eq.attrib['lon'])
        hdepth = float(eq.attrib['depth'])
        rake = float(eq.attrib['rake'])
        lstring = eq.attrib['locstring']
        description = eq.attrib['description']
        mech = eq.attrib['type']
        year = int(eq.attrib['year'])
        month = int(eq.attrib['month'])
        day = int(eq.attrib['day'])
        hour = int(eq.attrib['hour'])
        minute = int(eq.attrib['minute'])
        second = int(eq.attrib['second'])
        Directivity = ast.literal_eval(eq.attrib['directivity'])

    sdt = ShakeDateTime(year, month, day, hour, minute, second, int(0))

    #------------------------------------------
    # Read in rupture and make event dictionary
    #------------------------------------------
    cmd = 'ls %s/*fault-for-calc.txt' % (input_dir)
    rc, so, se = get_command_output(cmd)

    # probably need to add some error checking here

    ruptfile = so.decode('utf-8').strip()
    flt = fault.Fault.readFaultFile(ruptfile)
    event = {'lat': hlat,
             'lon': hlon,
             'depth': hdepth,
             'mag': magnitude,
             'rake': rake,
             'id': id_str,
             'locstring': lstring,
             'type': mech,
             'time': sdt.strftime('%Y-%m-%dT%H:%M:%SZ'),
             'timezone': 'UTC'}

    #------------------
    # Get list of GMPEs
    #------------------
    if args.gmpe == 'NSHMP14acr':
        gmpes = [AbrahamsonEtAl2014(), BooreEtAl2014(),
                 CampbellBozorgnia2014(), ChiouYoungs2014()]
        wts = [0.25, 0.25, 0.25, 0.25]
        #----------------------------------------------------
        # Note: we are not using Idriss' eqns for a few reasons:
        #      1) Does not include coefficients to compute PGV so we would need to use
        #         a conversion equation from another IM.
        #      2) His equations are not valid for Vs30 < 450 m/s.
        #      3) He does not seprate inter- and intra-event errors.
        #      4) The NHSMP will no longer be using it in the future.
        #----------------------------------------------------
    elif args.gmpe == 'NSHMP14scr_rlme':
        gmpes = [FrankelEtAl1996MwNSHMP2008(),
                 ToroEtAl1997MwNSHMP2008(),
                 SilvaEtAl2002MwNSHMP2008(),
                 Campbell2003MwNSHMP2008(),
                 TavakoliPezeshk2005MwNSHMP2008(),
                 AtkinsonBoore2006Modified2011(),
                 PezeshkEtAl2011(),
                 Atkinson2008prime(),
                 SomervilleEtAl2001NSHMP2008()]
        wts = [0.06, 0.11, 0.06, 0.11, 0.11, 0.22, 0.15, 0.08, 0.1]
        wts_largeR = [0.16, 0.0, 0.0, 0.17, 0.17, 0.3, 0.2, 0.0, 0.0]
    elif args.gmpe == 'NSHMP14scr_grd':
        gmpes = [FrankelEtAl1996MwNSHMP2008(),
                 ToroEtAl1997MwNSHMP2008(),
                 SilvaEtAl2002MwNSHMP2008(),
                 Campbell2003MwNSHMP2008(),
                 TavakoliPezeshk2005MwNSHMP2008(),
                 AtkinsonBoore2006Modified2011(),
                 PezeshkEtAl2011(),
                 Atkinson2008prime(),
                 SomervilleEtAl2001NSHMP2008()]
        wts = [0.06, 0.13, 0.06, 0.13, 0.13, 0.25, 0.16, 0.08, 0.0]
        wts_largeR = [0.16, 0.0, 0.0, 0.17, 0.17, 0.3, 0.2, 0.0, 0.0]
    elif args.gmpe == 'NSHMPsub_i':
        gmpes = [AtkinsonBoore2003SInter(), ZhaoEtAl2006SInter(),
                 AtkinsonMacias2009(), AbrahamsonEtAl2015SInter()]
        wts = [0.1, 0.3, 0.3, 0.3]
    elif args.gmpe == 'NSHMPsub_s':
        gmpes = [AtkinsonBoore2003SSlab(), AtkinsonBoore2003SSlabCascadia(),
                 ZhaoEtAl2006SSlab(), AbrahamsonEtAl2015SSlab()]
        wts = [0.1667, 0.1667, 0.33, 0.33]
    elif args.gmpe == 'ASK14':
        gmpes = [AbrahamsonEtAl2014()]
        wts = [1.0]
    elif args.gmpe == 'BSSA14':
        gmpes = [BooreEtAl2014()]
        wts = [1.0]
    elif args.gmpe == 'CB14':
        gmpes = [CampbellBozorgnia2014()]
        wts = [1.0]
    elif args.gmpe == 'CY14':
        gmpes = [ChiouYoungs2014()]
        wts = [1.0]
    elif args.gmpe == 'F96':
        gmpes = [FrankelEtAl1996MwNSHMP2008()]
        wts = [1.0]
    elif args.gmpe == 'T02':
        gmpes = [ToroEtAl1997MwNSHMP2008()]
        wts = [1.0]
    elif args.gmpe == 'S02':
        gmpes = [SilvaEtAl2002MwNSHMP2008()]
        wts = [1.0]
    elif args.gmpe == 'C03':
        gmpes = [Campbell2003MwNSHMP2008()]
        wts = [1.0]
    elif args.gmpe == 'TP05':
        gmpes = [TavakoliPezeshk2005MwNSHMP2008()]
        wts = [1.0]
    elif args.gmpe == 'AB06p':
        gmpes = [AtkinsonBoore2006Modified2011()]
        wts = [1.0]
    elif args.gmpe == 'P11':
        gmpes = [PezeshkEtAl2011()]
        wts = [1.0]
    elif args.gmpe == 'A08p':
        gmpes = [Atkinson2008prime()]
        wts = [1.0]
    elif args.gmpe == 'S01':
        gmpes = [SomervilleEtAl2001NSHMP2008()]
        wts = [1.0]
    elif args.gmpe == 'AB03ig':
        gmpes = [AtkinsonBoore2003SInter()]
        wts = [1.0]
    elif args.gmpe == 'Z06i':
        gmpes = [ZhaoEtAl2006SInter()]
        wts = [1.0]
    elif args.gmpe == 'AM09':
        gmpes = [AtkinsonMacias2009()]
        wts = [1.0]
    elif args.gmpe == 'BCH15i':
        gmpes = [AbrahamsonEtAl2015SInter()]
        wts = [1.0]
    elif args.gmpe == 'AB03sg':
        gmpes = [AtkinsonBoore2003SSlab()]
        wts = [1.0]
    elif args.gmpe == 'AB03sc':
        gmpes = [AtkinsonBoore2003SSlabCascadia()]
        wts = [1.0]
    elif args.gmpe == 'Z06s':
        gmpes = [ZhaoEtAl2006SSlab()]
        wts = [1.0]
    elif args.gmpe == 'BCH15s':
        gmpes = [AbrahamsonEtAl2015SSlab()]
        wts = [1.0]
    else:
        raise Exception('Specified an unsupported GMPE.')

    #----------------------------------------
    # Make source instance and compute extent
    #----------------------------------------
    source = Source(event, flt)

    lonmin, lonmax, latmin, latmax = get_extent(source)

    lats = flt.getLats()
    lons = flt.getLons()
    lon_mid = 0.5 * (np.nanmax(lons) + np.nanmin(lons))
    lat_mid = 0.5 * (np.nanmax(lats) + np.nanmin(lats))
    lonspan = float(lonmax - lonmin)
    latspan = float(latmax - latmin)

    # Adjust number of cells if necessary
    res = args.res
    nx = np.floor(lonspan / res) + 1
    ny = np.floor(latspan / res) + 1
    ncell = nx * ny
    nmax = args.max
    if ncell > nmax:
        res = (-(latspan + lonspan) -
               np.sqrt(latspan**2 + lonspan**2 + 2 * latspan * lonspan * (2 * nmax - 1))) /\
              (2 * (1 - nmax))
        warnings.warn(
            'resolution adjusted due to max number of cells allowed.')
        nx = np.floor(lonspan / res) + 1
        ny = np.floor(latspan / res) + 1
        ncell = nx * ny

    # Adjust extents to be divisible by res
    lonmin = res * np.round(lonmin / res)
    lonmax = res * np.round(lonmax / res)
    latmin = res * np.round(latmin / res)
    latmax = res * np.round(latmax / res)

    # Recompute latspan and lonspan
    lonspan = float(lonmax - lonmin)
    latspan = float(latmax - latmin)

    # buffer to increase grid so that it doesn't barf when sent to ShakeMap
    buf = 2 * res
    west = lon_mid - lonspan / 2.0 - buf
    east = lon_mid + lonspan / 2.0 + buf
    north = lat_mid + latspan / 2.0 + buf
    south = lat_mid - latspan / 2.0 - buf

    # Shakemap uses epicenter as ceter, solve for offsets to match
    latoff = hlat - lat_mid  # move map south
    lonoff = lon_mid - hlon  # move map east

    # Geodictionary for this ShakeMap
    tmpdict = {'xmin': west, 'xmax': east,
               'ymin': south, 'ymax': north,
               'dx': res, 'dy': res,
               'nx': nx, 'ny': ny}
    smdict = GeoDict(tmpdict, adjust='bounds')

    #---------------------
    # Make rupture context
    #---------------------
    rupt = source.getRuptureContext(gmpes)

    #--------------------------------
    # Vs30 stuff
    #--------------------------------
    vs30filename = args.vs30
    vs30grid = GMTGrid.load(vs30filename, smdict, resample=True)
    vs30geodict = vs30grid.getGeoDict()
    smdx = vs30geodict.dx
    smdy = vs30geodict.dy
    smnx = vs30geodict.nx
    smny = vs30geodict.ny
    bounds = (west, east, south, north)

    # Sites object
    sites_object = Sites(vs30grid)

    #----------------------------------------------------
    # Standard deviation stuff
    #----------------------------------------------------

    # Only use total standard deviation for scenarios since
    # we never had data to get bias.
    stddev_types = [const.StdDev.TOTAL]

    #----------------------------------------------------
    # Intensity measures
    #----------------------------------------------------

    # Mapping between the IM notation in ShakeMap and the
    # OpenQuake notation for the IMs taht we want
    imt_dict = {'pga': 'PGA', 'pgv': 'PGV', 'psa03': 'SA(0.3)',
                'psa10': 'SA(1.0)', 'psa30': 'SA(3.0)'}

    #----------------------------------------------------
    # Mesh calculations
    #----------------------------------------------------
    lats = np.linspace(north, south, smny)
    lons = np.linspace(west, east, smnx)
    lon, lat = np.meshgrid(lons, lats)
    dep = np.zeros_like(lon)

    # Compute distances and site parameters on mesh.
    dist = Distance(gmpes, source, lat, lon, dep)
    dctx = dist.getDistanceContext()
    # Sites context
    sites = SitesContext()
    sites.vs30 = vs30grid._data

    # Clip Vs30 do avoid out-of-bounds error:
    sites.vs30 = np.clip(sites.vs30, 0, 2000)

    sites.vs30measured = np.ones_like(sites.vs30, dtype=bool)

    # Add z1 and z2.5
    sites.z1pt0cy14 = mg._z1_from_vs30_cy14_cal(sites.vs30)
    sites.z1pt0ask14 = mg._z1_from_vs30_ask14_cal(sites.vs30)
    sites.z2pt5 = mg._z2p5_from_vs30_cb14_cal(sites.vs30) / 1000.0
    # note: function gives z2pt5 in m, but CB14 expect km.

    #----------------------------------------------------
    # Intensity measure calculation
    #----------------------------------------------------

    # Make a dictionary to store intensity measure(s) and
    # their sigmas.

    imdict = {'pga': {'mean': np.zeros(orig_shape), 'sigma': np.zeros(orig_shape)},
              'pgv': {'mean': np.zeros(orig_shape), 'sigma': np.zeros(orig_shape)},
              'psa03': {'mean': np.zeros(orig_shape), 'sigma': np.zeros(orig_shape)},
              'psa10': {'mean': np.zeros(orig_shape), 'sigma': np.zeros(orig_shape)},
              'psa30': {'mean': np.zeros(orig_shape), 'sigma': np.zeros(orig_shape)}}

    #----------------------------------------------------
    # Directivity
    #----------------------------------------------------
    if Directivity:
        R13 = Rowshandel2013.fromSites(
            source, sites_object, dx=1.0, T=[1.0, 3.0],
            a_weight=0.5, mtype=1)
        fd1 = R13.getFd()[0]
        fd3 = R13.getFd()[1]

    #----------------
    # Evaluarte GMPEs
    #----------------
    for key, val in imt_dict.items():
        iimt = imt.from_string(val)

        mgmpe = mg.MultiGMPE.from_list(gmpes, wts)
        lnmu, lnsd = mgmpe.get_mean_and_stddevs(
            sites, rupt, dctx, iimt, stddev_types)

        # Handle directivity factors
        # NOTE: currently, the Rowshandel model does not provide
        #       equations for adjusting sigma. Asssuming these are
        #       eventually available, need to move the sigma
        #       adjustment into this if-statement.
        if Directivity:
            if (key == 'pgv') | (key == 'psa10'):
                fd = fd1
            elif (key == 'psa30'):
                fd = fd3
            else:
                # no directivity for pga and psa03
                fd = 0

            lnmu = lnmu + fd

        # Put into intensity measure dictionary
        imdict[key]['mean'] = lnmu
        imdict[key]['sigma'] = lnsd

        #----------------------------------------------------
        # Write files
        #----------------------------------------------------

        # Loop over intensity dictionary (PGA PGV, PSA03, PSA10, PSA30)
        for key, val in imdict.items():
            if key != 'pgv':
                # Note that the output is in units of ln(g), whereas
                # ShakeMap wants %g
                mgrid = GMTGrid(100 * np.exp(imdict[key]['mean']), smdict)
                sgrid = GMTGrid(imdict[key]['sigma'], smdict)
            else:
                mgrid = GMTGrid(np.exp(imdict[key]['mean']), smdict)
                sgrid = GMTGrid(imdict[key]['sigma'], smdict)
            mgrid.save(os.path.join(input_dir, key + '_estimates.grd'))
            sgrid.save(os.path.join(input_dir, key + '_sd.grd'))

        # Directivity factors
        if Directivity:
            fd1grd = GMTGrid(fd1, smdict)
            fd3grd = GMTGrid(fd3, smdict)
            fd1grd.save(os.path.join(input_dir, 'fd1.grd'))
            fd3grd.save(os.path.join(input_dir, 'fd3.grd'))

        # MMI - get from PGV
        gmice = WGRW12()
        tmp_pgv = np.reshape(imdict['pgv']['mean'], (-1,))

        # Use rrup if available, otherwise rhypo
        if hasattr(dctx, 'rrup'):
            dist4gmice = dctx.rrup
        else:
            dist4gmice = dctx.rhypo

        mmi = gmice.getMIfromGM(np.exp(tmp_pgv), 'PGV',
                                dists=dist4gmice,
                                mag=rupt.mag)
        GM2MIsd = gmice.getGM2MIsd()['pgv']  # in 'intensity' units
        c = WGRW12._WGRW12__constants['pgv']
        c2 = WGRW12._WGRW12__constants2['pgv']
        lamps = np.log10(np.exp(mmi))
        dmmi_damp = np.zeros_like(lamps)
        idx = (lamps >= c2['T1']) & (lamps < c['T1'])
        dmmi_damp[idx] = c['C2']
        idx = lamps >= c['T1']
        dmmi_damp[idx] = c['C4']

        # convert to log10
        amp_sd = np.reshape(imdict['pgv']['sigma'], (-1,)) / np.log(10)
        additional_var = dmmi_damp**2 * (amp_sd**2)
        mmi_sd = np.sqrt(GM2MIsd**2 + additional_var)
        mmi = np.reshape(mmi, orig_shape)
        mmi_sd = np.reshape(mmi_sd, orig_shape)
        mgrid = GMTGrid(mmi, smdict)
        sgrid = GMTGrid(mmi_sd, smdict)
        mgrid.save(os.path.join(input_dir, 'mi_estimates.grd'))
        sgrid.save(os.path.join(input_dir, 'mi_sd.grd'))


if __name__ == '__main__':
    desc = '''
    Create the ShakeMap *_estimates.grd and *_sd.grd files. Requires an input 
    directory with event.xml and fault files; the inputs should be created by
    the 'mkinputdir' script or similar. 

    Currently any GMPE set besides NSHMP14acr (or any combination of its 
    constituent GMPEs) is likely to cause errors. 
    '''
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('-e', '--event',
                        help='Specifies the id of the event to process.')
    parser.add_argument('-v', '--vs30',
                        help='Specifies the path to the Vs30 grid to use.')
    parser.add_argument('-g', '--gmpe', default='NSHMP14acr',
                        help='Select GMPE(s).',
                        choices=['NSHMP14acr', 'NSHMP14scr_rlme', 'NSHMP14scr_grd',
                                 'NSHMPsub_i', 'NSHMPsub_s',
                                 'ASK14', 'BSSA14', 'CB14', 'CY14',
                                 'F96', 'T02', 'S02', 'C03', 'TP05', 'AB06p', 'P11', 'A08p', 'S01',
                                 'AB03ig', 'Z06i', 'BCH15i',
                                 'AB03sg', 'AB03sc', 'Z06s', 'BCH15s'])
    parser.add_argument('-r', '--res', default=30 / 60 / 60, type=float,
                        help='The resolution in decimal degrees; default is 30/60/60.')
    parser.add_argument('-m', '--max', default=500000, type=int,
                        help='Maximum number of cells allowed; '
                        'resolution is adjusted to ensure this number is not exceeded; '
                        'default is 500,000.')
    shakehome = os.path.join(os.path.expanduser('~'), 'ShakeMap')
    parser.add_argument('-s', '--shakehome',
                        help='the location of ShakeMap install; default is %s.' % shakehome)
    args = parser.parse_args()
    main(args)
